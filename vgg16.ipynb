{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "vgg16.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN1b1UZEb93Z8W2Z8nGDdN2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hongjieun123/deeplearning-project/blob/master/vgg16.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNmigkxeSfSh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "2638dc70-e7e3-4f01-c1c4-7abce87d5109"
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "\n",
        "# 구글 드라이브 mount \n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y4XzWZWvW63",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a260f40a-4d4b-4692-dce3-8a07b0f00336"
      },
      "source": [
        "# 1. 홈 디렉토리에 datasets 폴더 생성 후, 그 안에 cats_and_dogs_small 폴더를 생성 합니다.\n",
        "# 2. cats_and_dogs_small 안에 train, test, validation 폴더가 위치 하도록 압축을 풉니다.\n",
        "%cd gdrive/My Drive/datasets/cats_and_dogs_small"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/datasets/cats_and_dogs_small\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrspcc1Vyp5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator    #ImageDataGenerator  구글드라이브 사진 가져와 쓰겠다. \n",
        "\n",
        "# 모든 이미지를 1/255로 스케일을 조정합니다\n",
        "#0~255/255 -> 0~1사이로 만듦\n",
        "#image augmentation -> 같은 사진을 변형해서 여러 샘플을 만들어준다.\n",
        "# 모든 이미지를 1/255로 스케일을 조정합니다\n",
        "#내가 정해놓은 속성에 맞게 불러오겠다.\n",
        "# (batch, height, width, channel)\n",
        "# Numpy N-dims Array (60000, 28, 28, 1) batch_size = 4 --> (4, 28, 28, 1)\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, \n",
        "                                   shear_range = 0.2, \n",
        "                                   zoom_range = 0.2, \n",
        "                                   horizontal_flip = True)\n",
        "# Batch_size = 4 -> (4, 28, 28, 1)  \n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "base_dir = '/content/gdrive/My Drive/datasets/cats_and_dogs_small'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "test_dir = os.path.join(base_dir, 'test')\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # 타깃 디렉터리\n",
        "        train_dir,\n",
        "        # 모든 이미지를 224 × 224 크기로 바꿉니다(왜?? 입력데이터가 224x224로 고정되어 있기 때문)\n",
        "        target_size=(224, 224),  #이미지 사이즈\n",
        "        batch_size=20,   #몇장 가져올건지 (random하게 4장)\n",
        "        # binary_crossentropy 손실을 사용하기 때문에 이진 레이블이 필요합니다\n",
        "        class_mode='categorical') #가지고 온 데이터의 클래스\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=4,\n",
        "        class_mode='categorical')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCkVcTYT3xO0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "188d4c86-465e-4f94-ec2e-f0c24f277eb4"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# 모든 이미지를 1/255로 스케일을 조정합니다\n",
        "# (batch, height, width, channel)\n",
        "# Numpy N-dims Array (60000, 28, 28, 1) batch_size = 4 --> (4, 28, 28, 1)\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255, \n",
        "                                   shear_range = 0.2, \n",
        "                                   zoom_range = 0.2, \n",
        "                                   horizontal_flip = True)\n",
        "# Batch_size = 4 -> (4, 28, 28, 1)\n",
        "# Augmentation: Shear, Zoom, Flip\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "# Augmentation X , Scale [0~1]\n",
        "\n",
        "base_dir = '/content/gdrive/My Drive/datasets/cats_and_dogs_small'\n",
        "\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "test_dir  = os.path.join(base_dir, 'test')\n",
        "validation_dir = os.path.join(base_dir, 'validation')\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        # 타깃 디렉터리\n",
        "        train_dir,\n",
        "        # 모든 이미지를 224 × 224 크기로 바꿉니다\n",
        "        target_size=(224, 224),\n",
        "        batch_size=4,\n",
        "        # binary_crossentropy 손실을 사용하기 때문에 이진 레이블이 필요합니다\n",
        "        class_mode='categorical')\n",
        "# Binary 0 ~ 1\n",
        "# Categorical [1, 0] == 0\n",
        "#             [0, 1] == 1\n",
        "\n",
        "\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        validation_dir,\n",
        "        target_size=(224, 224),\n",
        "        batch_size=4,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Found 121 images belonging to 2 classes.\n",
            "Found 40 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-yKF0P5B3_z2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2d1a0b75-4281-4625-84a5-ff234b93aa07"
      },
      "source": [
        "for data_batch, labels_batch in train_generator:\n",
        "    print ('Batch size:', data_batch.shape)\n",
        "    print ('Label size:', labels_batch.shape)\n",
        "    break\n",
        "\n",
        "# One-Hot encoding Example\n",
        "# 2개 0, 1\n",
        "# 0: [1, 0]\n",
        "# 1: [0, 1]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch size: (4, 224, 224, 3)\n",
            "Label size: (4, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nTtO5PnR4BFZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "35ba1762-833a-46fe-92b0-665c7b04974e"
      },
      "source": [
        "print (train_generator.class_indices)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'cats': 0, 'dogs': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ll9RchP34LM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "364f589f-f00e-448c-eb90-cebb651b8022"
      },
      "source": [
        "#  This code cell shows how to utilize VGG16 model by combining Dense layer at the end of the network \n",
        "from keras.layers import Input, Dense, GlobalAveragePooling2D, Flatten\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras import layers\n",
        "from keras import models\n",
        "\n",
        "VGGNet = VGG16()\n",
        "VGGNet.summary()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 34s 0us/step\n",
            "Model: \"vgg16\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "fc1 (Dense)                  (None, 4096)              102764544 \n",
            "_________________________________________________________________\n",
            "fc2 (Dense)                  (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "predictions (Dense)          (None, 1000)              4097000   \n",
            "=================================================================\n",
            "Total params: 138,357,544\n",
            "Trainable params: 138,357,544\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_f-Yf7x4UEx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 963
        },
        "outputId": "d8401ebe-12a3-40c5-dad8-5d8799aa71d9"
      },
      "source": [
        "# We will not update VGG pre-trained model, only added Dense layers will be trained from the scratch\n",
        "for layer in VGGNet.layers:\n",
        "  layer.trainable = False  #학습 가능 여부 , 업데이트가 안되도록 막음. (frozen)\n",
        "  \n",
        "Feature_Flatten = VGGNet.get_layer('flatten').output\n",
        "\n",
        "dense = Dense(256, name='encoding', activation='relu')(Feature_Flatten)\n",
        "predictions = Dense(2, activation='softmax', name=\"prediction\")(dense)\n",
        "\n",
        "New_VGGmodel = Model(inputs=VGGNet.input, outputs=predictions)\n",
        "New_VGGmodel.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "New_VGGmodel.summary()\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
            "_________________________________________________________________\n",
            "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
            "_________________________________________________________________\n",
            "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
            "_________________________________________________________________\n",
            "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
            "_________________________________________________________________\n",
            "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
            "_________________________________________________________________\n",
            "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
            "_________________________________________________________________\n",
            "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
            "_________________________________________________________________\n",
            "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
            "_________________________________________________________________\n",
            "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
            "_________________________________________________________________\n",
            "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
            "_________________________________________________________________\n",
            "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
            "_________________________________________________________________\n",
            "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
            "_________________________________________________________________\n",
            "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "encoding (Dense)             (None, 256)               6422784   \n",
            "_________________________________________________________________\n",
            "prediction (Dense)           (None, 2)                 514       \n",
            "=================================================================\n",
            "Total params: 21,137,986\n",
            "Trainable params: 6,423,298\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5leu570f474P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "7c824a86-3984-4520-9043-bb6b2cf1da66"
      },
      "source": [
        "history = New_VGGmodel.fit_generator(\n",
        "    train_generator,\n",
        "    # validation_data=validation_generator, \n",
        "    # validation_steps=5,\n",
        "    # 20장 / batch_size 4 = 5\n",
        "    steps_per_epoch=50,\n",
        "    # 60장 / batch_size 4 = 15\n",
        "    epochs=5\n",
        "    # 전체 반복 횟수 입니다.\n",
        ")"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "15/15 [==============================] - 34s 2s/step - loss: 8.2538 - accuracy: 0.4912\n",
            "Epoch 2/5\n",
            "15/15 [==============================] - 31s 2s/step - loss: 2.3066 - accuracy: 0.6000\n",
            "Epoch 3/5\n",
            "15/15 [==============================] - 32s 2s/step - loss: 1.0123 - accuracy: 0.7500\n",
            "Epoch 4/5\n",
            "15/15 [==============================] - 29s 2s/step - loss: 1.1738 - accuracy: 0.7018\n",
            "Epoch 5/5\n",
            "15/15 [==============================] - 32s 2s/step - loss: 1.0319 - accuracy: 0.8167\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCfCqpRt471X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 310
        },
        "outputId": "f9320f73-fdb9-4dc8-ac15-fcb3073c59b5"
      },
      "source": [
        "pip install flickrapi"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flickrapi\n",
            "  Downloading https://files.pythonhosted.org/packages/76/d7/291b7f0f02cf0f59460f7bcc15192905b4c61e13b9fb9263ee86b0a5f647/flickrapi-2.4.0-py2.py3-none-any.whl\n",
            "Collecting requests-toolbelt>=0.3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/ef/7681134338fc097acef8d9b2f8abe0458e4d87559c689a8c306d0957ece5/requests_toolbelt-0.9.1-py2.py3-none-any.whl (54kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests-oauthlib>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from flickrapi) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5.2 in /usr/local/lib/python3.6/dist-packages (from flickrapi) (1.12.0)\n",
            "Requirement already satisfied: requests>=2.2.1 in /usr/local/lib/python3.6/dist-packages (from flickrapi) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.4.0->flickrapi) (3.1.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->flickrapi) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->flickrapi) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->flickrapi) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.2.1->flickrapi) (2.9)\n",
            "Installing collected packages: requests-toolbelt, flickrapi\n",
            "Successfully installed flickrapi-2.4.0 requests-toolbelt-0.9.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vi31AYj047zl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na798Oru47w3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1nadvz947tb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYUjjUcO47q6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxAf9xHG47ox",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uX6rg5in47lI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}